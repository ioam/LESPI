{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import lancet\n",
    "import holoviews as hv\n",
    "\n",
    "from featuremapper.analysis.raster import fft_power\n",
    "from featuremapper.analysis.pinwheels import PinwheelAnalysis\n",
    "from featuremapper.analysis.hypercolumns import PowerSpectrumAnalysis\n",
    "from topo.analysis.command import *\n",
    "from analysis import *\n",
    "\n",
    "import topo\n",
    "from topo.analysis import Collector\n",
    "from topo.submodel.scal import ModelSCAL\n",
    "from topo.submodel.gcal import ArraySpec\n",
    "\n",
    "from topo.command import runscript  # In order to check the model files load correctly\n",
    "from topo.misc.lancext import RunBatchCommand, topo_metadata\n",
    "\n",
    "hv.notebook_extension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Setup\n",
    "\n",
    "### Defining the parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_name = 'SCAL_spatial'\n",
    "\n",
    "# Model options\n",
    "laterals = True\n",
    "\n",
    "# Measurements\n",
    "rfs = True\n",
    "isosuppression = True\n",
    "sizetuning = True\n",
    "frequencytuning = True\n",
    "complexity = False\n",
    "flankers = True\n",
    "\n",
    "# Define times\n",
    "times = [1000*i for i in range(21)]\n",
    "print(\"Collection times start at %s and end at %s\" % (min(times), max(times)))\n",
    "\n",
    "# Define Args\n",
    "constants = lancet.Args(area=4.0, aff_strength=2.4, exc_strength=1.6, inh_strength=1.8,\n",
    "                        cortex_density=47, lgn_density=16, laterals=laterals, t_settle=16,)\n",
    "batch_arguments = constants * lancet.Args(times=times) * lancet.List('dataset', ['Gaussian', 'natural', 'treeshrew'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topo.sim.model = ModelSCAL(laterals=laterals, area=1.0)\n",
    "scal = topo.sim.model.specification\n",
    "topo.sim.model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the measurements and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = Collector()\n",
    "\n",
    "# Projection activities\n",
    "c.Activity.LGNOnAfferent =  c.collect(scal.projections.V1.LGNOnAfferent)\n",
    "c.Activity.LGNOffAfferent = c.collect(scal.projections.V1.LGNOffAfferent)\n",
    "\n",
    "# OR preference measurement\n",
    "c.collect(measure_or_pref)\n",
    "# Sheet activities\n",
    "c.Activity.Retina =         c.collect(scal.sheets.Retina)\n",
    "c.Activity.V1 =             c.collect(scal.sheets.V1)\n",
    "# Connection fields\n",
    "c.CFs.LGNOnAfferent =       c.collect(scal.projections.V1.LGNOnAfferent,  grid=True)\n",
    "c.CFs.LGNOffAfferent =      c.collect(scal.projections.V1.LGNOffAfferent, grid=True)\n",
    "c.CFs.LateralInhibitory =   c.collect(scal.projections.V1.LateralInhibitory, grid=True)\n",
    "c.CFs.LateralExcitatory =   c.collect(scal.projections.V1.LateralExcitatory, grid=True)\n",
    "if laterals:\n",
    "    c.CFs.LRExcitatory =   c.collect(scal.projections.V1.LRExcitatory, rows=47, cols=47,\n",
    "                                     grid=True, bounds=(-.5, -.5, .5, .5))\n",
    "\n",
    "# Homeostatic threshold\n",
    "c.HomeostaticThreshold.V1 = c.collect(ArraySpec('V1.output_fns[0].t'), \n",
    "                                                group='Homeostatic Threshold')\n",
    "\n",
    "# OR preference measurement\n",
    "c.collect(measure_or_pref, frequencies=[1.4, 1.6, 1.8])\n",
    "c.collect(measure_response, durations=list(np.linspace(0, 1, 21)))\n",
    "c.collect(measure_or_tuning_fullfield, contrasts=[5, 10, 20, 30, 50, 70, 100],\n",
    "          frequencies=[1.4, 1.6, 1.8], times=[times[-1]])\n",
    "\n",
    "if rfs:\n",
    "    c.collect(measure_rfs, roi=(-.25, -.25, .25, .25), presentations=5000, scale=100, outputs=['V1'], times=[times[-1]])\n",
    "\n",
    "# Times and coords for further measurements\n",
    "coords=[(0,-0.1),(-0.1,0.0),(0,0),(0,0.1),(0.1,0.0)]\n",
    "frequency=1.6\n",
    "\n",
    "# Analysis\n",
    "c.Pinwheels.V1   = c.analyze(c.ref.OrientationPreference.V1[:, -1.5:1.5, -1.5:1.5]\n",
    "                             * c.ref.OrientationSelectivity.V1[:, -1.5:1.5, -1.5:1.5], PinwheelAnalysis)\n",
    "c.FFTAnalysis.V1 = c.analyze(c.ref.OrientationPreference.V1[:, -1.5:1.5, -1.5:1.5], PowerSpectrumAnalysis)\n",
    "\n",
    "# Measure position preference, requisite for other measurements\n",
    "if sizetuning or frequencytuning or flankers or complexity or isosuppression:\n",
    "    c.collect(measure_position_pref, x_range=(-0.4,0.4), y_range=(-0.4,0.4),\n",
    "              size=0.1, outputs=['V1'], divisions=36, scale=2.0)\n",
    "\n",
    "# Orientation Contrast Suppression\n",
    "if isosuppression:\n",
    "    c.analyze(c.ref.OrientationPreference.V1, measure_iso_suppression, output='V1',\n",
    "              frequency=frequency, contrastcenter=70, contrastsurround=[10, 30, 70, 100],\n",
    "              times=[times[-1]], mode='merge')\n",
    "\n",
    "# Size Tuning Analysis\n",
    "if sizetuning:\n",
    "    c.analyze(c.ref.OrientationPreference.V1, measure_size_tuning, num_phase=8, outputs=['V1'],\n",
    "              coords=coords, frequency=frequency, contrasts=[10, 100], times=[times[-1]], mode='merge')\n",
    "\n",
    "# Measure PhaseTuning and Complexity\n",
    "if complexity:\n",
    "    c.analyze(c.ref.OrientationPreference.V1, measure_phase_tuning, outputs=['V1'], frequencies=[frequency],\n",
    "              num_orientation=12, times=times, mode='merge')\n",
    "    c.analyze(c.ref.PhaseTuning.V1, ComplexityAnalysis, times=[times[-1]], mode='merge')\n",
    "\n",
    "# Measure flanker modulation\n",
    "if flankers:\n",
    "    c.collect(measure_flanker_ormodulation, coords=coords, outputs=['V1'], times=[times[-1]])\n",
    "    c.collect(measure_flanker_xoffsetmodulation, coords=coords, outputs=['V1'], times=[times[-1]])\n",
    "    c.collect(measure_flanker_yoffsetmodulation, coords=coords, outputs=['V1'], times=[times[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching the jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Local or on cluster\n",
    "QSUB = False\n",
    "# Open diff in pager or not\n",
    "SHOW_DIFF = True\n",
    "\n",
    "ty_file = './scal_divisive.ty'\n",
    "metadata = topo_metadata()\n",
    "output_directory = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "lancet.review_and_launch.output_directory = output_directory\n",
    "\n",
    "qsub_options = dict(b='y',\n",
    "                    pe=('memory-2G', '4'),   # Parallel environment allocation\n",
    "                    v='OMP_NUM_THREADS=4',   # Must match slot allocation above.\n",
    "                    #l='h_rt=05:59:00',       # Time resource allocation \n",
    "                    P='inf_ndtc')            # Project\n",
    "\n",
    "@lancet.review_and_launch()\n",
    "def launch():\n",
    "    runbatch_cmd = RunBatchCommand(ty_file, c, metadata=batch_arguments.varying_keys)\n",
    "    Launcher = lancet.QLauncher if QSUB else lancet.Launcher\n",
    "    return Launcher(batch_name, batch_arguments, runbatch_cmd,  metadata=metadata(), \n",
    "                    **({'qsub_flag_options':qsub_options} if QSUB else {'max_concurrency': 3}))\n",
    "launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from holoviews.core.io import Unpickler\n",
    "from analysis.progress import ProgressWidget, load_table\n",
    "hv.notebook_extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = './data/2016-03-19_2017-SCAL_spatial'\n",
    "table = load_table(path)\n",
    "data = Unpickler.collect(table, drop=['time', 'Index', 'tid', 'timestamps'])\n",
    "ProgressWidget(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat ./data/2016-03-19_2017-SCAL_spatial/streams/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hv.notebook_extension('matplotlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pinwheel Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orpref = data.OrientationPreference.V1.select(time=20000)().select(x=(-1.5, 1.5), y=(-1.5, 1.5))\n",
    "PowerSpectrumAnalysis(orpref.reindex(['dataset'])).display('all').cols(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DoG Size Tuning Fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%output size=150 dpi=300 fig='svg'\n",
    "%%opts Histogram (edgecolor='k' facecolor='white') [fontsize={'xlabel':15, 'ticks':14}]\n",
    "%%opts Overlay [yaxis=None show_frame=False aspect=1.5]\n",
    "%%opts Layout [sublabel_position=(-0.15, 0.85) aspect_weight=1 hspace=0.3]\n",
    "sizetuning = data.SizeTuning.V1.select(dataset='Gaussian')()\n",
    "df = sizetuning.last.data\n",
    "peak_mean = df['Peak Size'].mean()\n",
    "peak_median = df['Peak Size'].median()\n",
    "surr_mean = df['Suppression Size'].mean()\n",
    "surr_median = df['Suppression Size'].median()\n",
    "peak_arrow = hv.Arrow(peak_median, 0, '', 'v')\n",
    "surr_arrow = hv.Arrow(surr_median, 0, '', 'v')\n",
    "\n",
    "size_tuning = ((hv.Table(df).hist(dimension='Peak Size', adjoin=False, num_bins=11)\\\n",
    " .clone(kdims=[hv.Dimension('$r_c$', unit='$\\circ$')]) * peak_arrow).relabel('Size tuning center') +\n",
    "(hv.Table(df).hist(dimension='Suppression Size', adjoin=False, num_bins=11)\\\n",
    " .clone(kdims=[hv.Dimension('$r_s$', unit='$\\circ$')]) * surr_arrow).relabel('Size tuning surround'))\n",
    "size_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hv.Store.dump(size_tuning, open('SCAL_SizeTuning.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppression Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%output dpi=120 size=120\n",
    "%%opts Overlay [aspect=1.5 show_frame=False]\n",
    "si_dist = (hv.Table(df).hist(dimension='SI', adjoin=False).relabel(group='Suppression Index') *\n",
    "           hv.Text(0.6, 3, 'Mean SI: $%.3f \\pm %.3f$' % (df.SI.mean(), ss.sem(df.SI)), fontsize=10))\n",
    "si_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area summation/size tuning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sizeresponse = data.SizeResponse.V1()\n",
    "size_curves = hv.GridSpace(kdims=['X', 'Y'])\n",
    "for (x, y), responses in sizeresponse.groupby(['X', 'Y']).items():\n",
    "    sampled = responses.sample((5, 5), bounds=(x-0.05, y-0.05, x+0.05, y+0.05))\n",
    "    size_curves[x, y] = sampled.to.curve(['Size'], ['Response']).overlay('Contrast').grid(['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size_grid = size_curves.values()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%opts GridSpace [fig_size=200]\n",
    "size_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%output dpi=120 size=120\n",
    "%%opts NdOverlay [aspect=1.5] Layout [aspect_weight=0.5]\n",
    "size_grid[0.03, -.1].relabel(group='Size Tuning') + size_grid[0.01, -.14].relabel(group='Size Tuning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrast dependent size tuning shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "contrast_shift = data.ContrastShift.V1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = contrast_shift.hist(dimension='CSS', adjoin=False, bin_range=(0.8, 1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%output dpi=120 size=120\n",
    "%%opts Overlay [aspect=1.5 show_frame=False]\n",
    "css_dist = (contrast_shift.hist(dimension='CSS', adjoin=False, bin_range=(0.8, 1.5)).values()[0] *\n",
    "            hv.Text(1.3, 8, 'Mean CSS: $%.3f \\pm %.3f$' % (contrast_shift.last.data.CSS.mean(),\n",
    "                                            ss.sem(contrast_shift.last.data.CSS)), fontsize=10))\n",
    "css_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orientation contrast suppression index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ocsi = data.OCSI_Analysis.V1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%output dpi=120 size=120\n",
    "%%opts Overlay [aspect=1.5 show_frame=False]\n",
    "ocsi_high = ocsi['Gaussian', 20000, 100]\n",
    "ocsi_high_df = ocsi_high.data.dropna()\n",
    "ocsi_dist = (ocsi_high.hist(adjoin=False, bin_range=(0, 1.2), normed=False) *\n",
    "             hv.Text(0.5, 20, 'Mean OCSI: $%.3f \\pm %.3f$' % (ocsi_high_df[ocsi_high_df.OCSI > -6].OCSI.mean(),\n",
    "                                                             ss.sem(ocsi_high_df[ocsi_high_df.OCSI > -6].OCSI)),\n",
    "                     fontsize=10))\n",
    "ocsi_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%output widgets='live'\n",
    "%%opts Image (cmap='RdBu_r')\n",
    "orcontrast.select(x=(-.1, 0.1), y=(-.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orcontrast = data.OrientationContrastResponse.V1.select(dataset='natural')()\n",
    "ocsi_curves = hv.GridSpace(kdims=['X', 'Y'])\n",
    "for (x, y), responses in orcontrast.groupby(['X', 'Y']).items():\n",
    "    ocsi_curves[x, y] = responses.sample((5, 5), bounds=(x-0.05, y-0.05, x+0.05, y+0.05)).to.curve(['OrientationSurround'], ['Response']).overlay('ContrastSurround').grid(['x', 'y'])\n",
    "ocsi_grid = ocsi_curves.values()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%opts Curve [xticks=5]\n",
    "ocsi_grid.map(lambda x: hv.Scatter(x)[-np.pi/2: np.pi/2.], [hv.Curve])[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%output dpi=120 size=120\n",
    "%%opts Histogram {+axiswise} (facecolor='white') Text {+axiswise}\n",
    "surround_tuning = si_dist + css_dist + ocsi_dist\n",
    "surround_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hv.Store.dump(surround_tuning, open('SCAL_Surround.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orientation Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%output size=150\n",
    "%%opts NdOverlay [xaxis=None]\n",
    "ortuning = data.OrientationTuning.V1()\n",
    "ortuning_samples = ortuning.sample((8, 8))\n",
    "tuning_grid = ortuning_samples.to.curve('Orientation', 'Response').overlay('Contrast').grid(['x', 'y'])\n",
    "tuning_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuning_overlay = tuning_grid[1.76, 1.24].last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalized_tuning = tuning_overlay.clone(shared_data=False)\n",
    "for key, curve in tuning_overlay.items():\n",
    "    curve_data = curve.columns()\n",
    "    max_r = curve.range('Response')[1]\n",
    "    max_r = max_r if max_r else 1\n",
    "    curve_data['Normalized Response'] = curve_data['Response']/max_r\n",
    "    normalized_tuning[key] = curve.clone(curve_data, vdims=['Normalized Response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%opts NdOverlay [aspect=1.5] Layout [fig_size=150]\n",
    "tuning_overlay + normalized_tuning(style={'Curve': dict(color=hv.core.options.Palette('gray', reverse=True))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuning_overlay[10].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Distrubtion Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from topo.analysis.weights import WeightDistribution, WeightIsotropy\n",
    "\n",
    "latinh = data.CFs.LateralInhibitory.select(time=20000)()\n",
    "orpref = data.OrientationPreference.V1.select(time=20000)()\n",
    "xpref = data.XPreference.V1.select(time=20000)()\n",
    "ypref = data.YPreference.V1.select(time=20000)()\n",
    "\n",
    "tree = hv.Layout()\n",
    "tree.OrientationPreference.V1 = orpref.last\n",
    "tree.XPreference.V1 = xpref.last\n",
    "tree.YPreference.V1 = ypref.last\n",
    "tree.CFs.LateralInhibitory = latinh\n",
    "\n",
    "weight_orientation = WeightDistribution(tree, projections=[('V1', 'LateralInhibitory')])\n",
    "weight_isotropy = WeightIsotropy(tree, projections=[('V1', 'LateralInhibitory')], num_bins=10)\n",
    "weight_orientation + weight_isotropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = hv.Layout()\n",
    "tree.CFs.LRExcitatory = data.CFs.LRExcitatory.select(time=20000)()[-1:1, -1:1]\n",
    "tree.OrientationPreference.V1 = data.OrientationPreference.V1.select(time=20000)()\n",
    "vonMises = analysis.CFvonMisesFit(tree, sheet='V1', projection='LRExcitatory', fit_aspect=True, threshold=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vonMises.Results.Table.dframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%output size=150\n",
    "(vonMises.Preprocessed.CFs + hv.Empty() +\\\n",
    "vonMises.NaiveFit.CFs + vonMises.NaiveFit.Error +\\\n",
    "vonMises.VonMisesFit.CFs + vonMises.VonMisesFit.Error).cols(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%opts Distribution (kde_kws=dict(bw=0.5, cut=0) hist=True) {+axiswise} Overlay [aspect=2] Layout [fig_size=150] \n",
    "%%opts VLine (color='k') {+axiswise} Text {+axiswise}\n",
    "lat_fit_table = table.select(dataset='Gaussian', Model='vonMises', mu1=(0, 10))\n",
    "txt = '$\\sigma_{{{0}}} = {1:.5g} mm$'\n",
    "mean_mu1 = np.mean(lat_fit_table.data.mu1*3)\n",
    "mean_mu2 = np.mean(lat_fit_table.data.mu2*3)\n",
    "hv.Distribution(lat_fit_table.data.mu1*3) * hv.VLine(mean_mu1) * hv.Text(mean_mu1, 0.8, txt.format('LR', mean_mu1)) +\\\n",
    "hv.Distribution(lat_fit_table.data.mu2*3) * hv.VLine(mean_mu2) *  hv.Text(mean_mu2, 6, txt.format('LOC', mean_mu2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%opts BoxWhisker [aspect=1 fig_size=100]\n",
    "vonMises.Results.Table.table().to.box(['Model'], 'MSE', ['dataset']).layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%opts BoxWhisker [aspect=1 fig_size=100]\n",
    "vonMises.Results.Table.table().select(Model='vonMises').to.box(['dataset'], 'aspect', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%opts BoxWhisker [aspect=1 fig_size=100]\n",
    "vonMises.Results.Table.table().to.box(['Model'], 'r2', ['dataset']).layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfs = data.Retina_Reverse_Correlation.V1()\n",
    "orpref = data.OrientationPreference.V1.select(Time=20000)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rffit = RFGaborFit(rfs, orpref, roi_radius=1, max_iterations=10000)\n",
    "fit_table = rffit.RFGaborFit.RF_Fit_Values.table()\n",
    "fit_table.data['Time'] = fit_table.data.Time.astype(np.float)\n",
    "fit_table.data['Duration'] = fit_table.data.Duration.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%opts Image {+framewise +axiswise} GridSpace [normalize=True]\n",
    "(rffit.RFGaborFit.RF_Normed + rffit.RFGaborFit.RF_Fit).cols(2).display('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sliced = fit_table.select(f=(0,10), nx=(0, 2), ny=(0,2))\n",
    "hv.Layout([sliced.to.box(['dataset'], [value], []) for value in ['residual', 'f', 'nx']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%opts NdOverlay [fig_size=250]\n",
    "fit_table.to.scatter(['nx'], ['ny'], ['dataset'])[:, 0:1, 0:1].overlay()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
